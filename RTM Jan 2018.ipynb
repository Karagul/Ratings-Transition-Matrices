{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "import datetime\n",
    "import urllib.parse\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moodys loaded in 25.8619074 seconds\n",
      "sp loaded in 21.055627 seconds\n",
      "fitch loaded in 14.679695299999999 seconds\n",
      "converting to 8 digit cusip\n"
     ]
    }
   ],
   "source": [
    "# load the agency ratings\n",
    "ar = AgencyRatings()\n",
    "ar.load_agency_data(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2844: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9173, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the baml data on a specified date\n",
    "def get_baml_from_database(date):\n",
    "    db_connection_string = \"Uid=quant;Pwd=r4st3tee;Driver={SQL Server Native Client 11.0};Initial Catalog=Baml;\" \\\n",
    "                                           \"Server=csnydata01.creditsights.net\\csnext;Database=Baml;\"\n",
    "\n",
    "    # Setup database connection\n",
    "    params = urllib.parse.quote_plus(db_connection_string)\n",
    "    sqlalchemy = create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "\n",
    "    sql = \"\"\"SELECT *\n",
    "    FROM dbo.flattened_w_index\n",
    "    WHERE date = '{}'\n",
    "    AND (index_name = 'C0A0' OR index_name = 'H0A0')\n",
    "    \"\"\".format(date)\n",
    "\n",
    "    # read data\n",
    "    baml = pd.read_sql_query(sql, sqlalchemy)\n",
    "    \n",
    "    return baml\n",
    "\n",
    "start_date = datetime.date(2016,12,31)\n",
    "end_date = datetime.date(2017,12,31)\n",
    "\n",
    "# 1. get the starting values (t = 0)\n",
    "\n",
    "# get the baml constituents on 12/31/2016 (Jan 2017 constituents)\n",
    "baml = get_baml_from_database('2017-01-03')\n",
    "\n",
    "# get the 12/31/2016 agency ratings for the constituent set \n",
    "baml = ar.get_agency_ratings_by_id(data = baml, id_col = 'cusip', date = start_date)\n",
    "baml = ar.get_average_ratings(data = baml, \n",
    "                              require_two_agencies = False)\n",
    "\n",
    "baml['mkt_val'] = (baml['price'] / 100) * baml['face_value_loc']\n",
    "baml['mkt_val'] += (baml['face_value_loc'] / 100) * baml['accrued_interest']\n",
    "\n",
    "# keep selected columns and rename them\n",
    "baml_start  = baml[['cusip', 'ticker', 'description', 'ml_industry_lvl_3', 'ml_industry_lvl_4',\n",
    "                    'average_rating', 'prevmend_oas', 'mkt_val']]\n",
    "baml_start.rename(columns = {'average_rating': 'average_rating_0',\n",
    "                            'prevmend_oas': 'oas_0'}, inplace = True)\n",
    "\n",
    "# 2. get the ending values (t = 1)\n",
    "# again, get the baml constituents on 12/31/2016 (Jan 2017 constituents)\n",
    "baml = get_baml_from_database('2017-01-03')\n",
    "baml = baml[['cusip']]\n",
    "\n",
    "# now get the spreads of bonds that were in the index a year later on 12/31/2017\n",
    "baml_end = get_baml_from_database('2017-12-31')\n",
    "baml_end = baml_end[['cusip', 'oas']]\n",
    "baml = baml.merge(baml_end, how = 'left', on = 'cusip')\n",
    "\n",
    "\n",
    "# get the 12/31/2017 agency ratings for the constituent set \n",
    "baml_end = ar.get_agency_ratings_by_id(data = baml, id_col = 'cusip', date = end_date)\n",
    "baml_end = ar.get_average_ratings(data = baml_end, \n",
    "                              require_two_agencies = False)\n",
    "# keep selected columns and rename them\n",
    "baml_end  = baml_end[['cusip', 'average_rating', 'oas']]\n",
    "baml_end.rename(columns = {'average_rating': 'average_rating_1',\n",
    "                            'oas': 'oas_1'}, inplace = True)\n",
    "\n",
    "# 3. combine the 'start' view with the 'end' view\n",
    "baml = baml_start.merge(baml_end, how = 'left', on = 'cusip')\n",
    "\n",
    "# get the change in oas over the period\n",
    "baml['oas_change'] = baml['oas_1'] - baml['oas_0']\n",
    "baml.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baml.to_csv('baml_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>Count</th>\n",
       "      <th>AAA</th>\n",
       "      <th>AA1</th>\n",
       "      <th>AA2</th>\n",
       "      <th>AA3</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>BBB1</th>\n",
       "      <th>...</th>\n",
       "      <th>BB3</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>CCC1</th>\n",
       "      <th>CCC2</th>\n",
       "      <th>CCC3</th>\n",
       "      <th>CC</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AAA</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-19.750322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AA1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-22.831069</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AA2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-25.923556</td>\n",
       "      <td>-32.593277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AA3</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-36.904409</td>\n",
       "      <td>-28.821091</td>\n",
       "      <td>-25.371171</td>\n",
       "      <td>-7.612057</td>\n",
       "      <td>-45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A1</td>\n",
       "      <td>649.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.319776</td>\n",
       "      <td>-30.492409</td>\n",
       "      <td>-28.218615</td>\n",
       "      <td>-20.901243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A2</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-24.019827</td>\n",
       "      <td>-27.552365</td>\n",
       "      <td>-38.448717</td>\n",
       "      <td>-87.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A3</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23.141501</td>\n",
       "      <td>-35.137080</td>\n",
       "      <td>-26.155654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BBB1</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-49.901220</td>\n",
       "      <td>-41.666789</td>\n",
       "      <td>-33.629949</td>\n",
       "      <td>...</td>\n",
       "      <td>178.453228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BBB2</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.192409</td>\n",
       "      <td>-48.643724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BBB3</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-112.000000</td>\n",
       "      <td>-81.736869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BB1</td>\n",
       "      <td>248.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-152.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BB2</td>\n",
       "      <td>273.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.916985</td>\n",
       "      <td>62.769631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BB3</td>\n",
       "      <td>271.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.828463</td>\n",
       "      <td>-65.782123</td>\n",
       "      <td>742.300369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B1</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-86.183503</td>\n",
       "      <td>-51.237668</td>\n",
       "      <td>-14.525858</td>\n",
       "      <td>435.125545</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B2</td>\n",
       "      <td>245.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-66.237798</td>\n",
       "      <td>-77.799033</td>\n",
       "      <td>-75.227898</td>\n",
       "      <td>-38.748805</td>\n",
       "      <td>268.451821</td>\n",
       "      <td>379.900169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B3</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-135.000000</td>\n",
       "      <td>-272.569380</td>\n",
       "      <td>-108.566879</td>\n",
       "      <td>-43.325745</td>\n",
       "      <td>227.721799</td>\n",
       "      <td>878.324309</td>\n",
       "      <td>468.268244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CCC1</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-118.000000</td>\n",
       "      <td>-464.000000</td>\n",
       "      <td>-351.786667</td>\n",
       "      <td>-113.428536</td>\n",
       "      <td>-201.746557</td>\n",
       "      <td>-113.133723</td>\n",
       "      <td>842.344175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7086.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCC2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-136.000000</td>\n",
       "      <td>-644.000000</td>\n",
       "      <td>-202.466341</td>\n",
       "      <td>-138.478448</td>\n",
       "      <td>599.650338</td>\n",
       "      <td>1237.271474</td>\n",
       "      <td>1117.697986</td>\n",
       "      <td>482.771192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCC3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-263.000000</td>\n",
       "      <td>-412.000000</td>\n",
       "      <td>-1159.531394</td>\n",
       "      <td>298.944283</td>\n",
       "      <td>49.093486</td>\n",
       "      <td>-599.571681</td>\n",
       "      <td>2693.122246</td>\n",
       "      <td>6439.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-423.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1139.962229</td>\n",
       "      <td>4218.809324</td>\n",
       "      <td>4513.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-403.000000</td>\n",
       "      <td>-1235.477376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start   Count        AAA        AA1        AA2        AA3         A1  \\\n",
       "21   AAA    89.0 -19.750322   0.000000   0.000000   0.000000   0.000000   \n",
       "20   AA1    56.0   0.000000 -22.831069   3.000000   0.000000   0.000000   \n",
       "19   AA2    88.0   0.000000   0.000000 -25.923556 -32.593277   0.000000   \n",
       "18   AA3   450.0   0.000000   0.000000 -36.904409 -28.821091 -25.371171   \n",
       "17    A1   649.0   0.000000   0.000000   0.000000 -12.319776 -30.492409   \n",
       "16    A2  1081.0   0.000000   0.000000   0.000000   0.000000 -24.019827   \n",
       "15    A3  1066.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "14  BBB1  1345.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "13  BBB2  1277.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "12  BBB3  1012.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "11   BB1   248.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "10   BB2   273.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "9    BB3   271.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "8     B1   214.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "7     B2   245.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "6     B3   188.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "5   CCC1   135.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "4   CCC2    75.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3   CCC3    40.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "2     CC    13.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1      C     5.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "0      D     0.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "           A2          A3       BBB1     ...              BB3          B1  \\\n",
       "21   0.000000    0.000000   0.000000     ...         0.000000    0.000000   \n",
       "20   0.000000    0.000000   0.000000     ...         0.000000    0.000000   \n",
       "19   0.000000    0.000000   0.000000     ...         0.000000    0.000000   \n",
       "18  -7.612057  -45.000000   0.000000     ...         0.000000    0.000000   \n",
       "17 -28.218615  -20.901243   0.000000     ...         0.000000    0.000000   \n",
       "16 -27.552365  -38.448717 -87.000000     ...         0.000000    0.000000   \n",
       "15 -23.141501  -35.137080 -26.155654     ...         0.000000    0.000000   \n",
       "14 -49.901220  -41.666789 -33.629949     ...       178.453228    0.000000   \n",
       "13   0.000000  -56.192409 -48.643724     ...         0.000000    0.000000   \n",
       "12   0.000000 -112.000000 -81.736869     ...         0.000000    0.000000   \n",
       "11   0.000000    0.000000   0.000000     ...      -152.000000   19.000000   \n",
       "10   0.000000    0.000000   0.000000     ...       -87.916985   62.769631   \n",
       "9    0.000000    0.000000   0.000000     ...       -48.828463  -65.782123   \n",
       "8    0.000000    0.000000   0.000000     ...       -86.183503  -51.237668   \n",
       "7    0.000000    0.000000   0.000000     ...       -66.237798  -77.799033   \n",
       "6    0.000000    0.000000   0.000000     ...      -135.000000 -272.569380   \n",
       "5    0.000000    0.000000   0.000000     ...      -118.000000 -464.000000   \n",
       "4    0.000000    0.000000   0.000000     ...         0.000000    0.000000   \n",
       "3    0.000000    0.000000   0.000000     ...         0.000000    0.000000   \n",
       "2    0.000000    0.000000   0.000000     ...         0.000000    0.000000   \n",
       "1    0.000000    0.000000   0.000000     ...         0.000000    0.000000   \n",
       "0    0.000000    0.000000   0.000000     ...         0.000000    0.000000   \n",
       "\n",
       "            B2          B3         CCC1        CCC2        CCC3           CC  \\\n",
       "21    0.000000    0.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "20    0.000000    0.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "19    0.000000    0.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "18    0.000000    0.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "17    0.000000    0.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "16    0.000000    0.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "15    0.000000    0.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "14    0.000000    0.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "13    0.000000    0.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "12    0.000000    0.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "11    0.000000    0.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "10    0.000000  202.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "9   742.300369    0.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "8   -14.525858  435.125545   141.000000    0.000000    0.000000     0.000000   \n",
       "7   -75.227898  -38.748805   268.451821  379.900169    0.000000     0.000000   \n",
       "6  -108.566879  -43.325745   227.721799  878.324309  468.268244     0.000000   \n",
       "5  -351.786667 -113.428536  -201.746557 -113.133723  842.344175     0.000000   \n",
       "4  -136.000000 -644.000000  -202.466341 -138.478448  599.650338  1237.271474   \n",
       "3  -263.000000 -412.000000 -1159.531394  298.944283   49.093486  -599.571681   \n",
       "2     0.000000    0.000000     0.000000 -423.000000    0.000000  1139.962229   \n",
       "1     0.000000    0.000000     0.000000    0.000000 -403.000000 -1235.477376   \n",
       "0     0.000000    0.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "\n",
       "              C            D  \n",
       "21     0.000000     0.000000  \n",
       "20     0.000000     0.000000  \n",
       "19     0.000000     0.000000  \n",
       "18     0.000000     0.000000  \n",
       "17     0.000000     0.000000  \n",
       "16     0.000000     0.000000  \n",
       "15     0.000000     0.000000  \n",
       "14     0.000000     0.000000  \n",
       "13     0.000000     0.000000  \n",
       "12     0.000000     0.000000  \n",
       "11     0.000000     0.000000  \n",
       "10     0.000000     0.000000  \n",
       "9      0.000000     0.000000  \n",
       "8      0.000000     0.000000  \n",
       "7      0.000000     0.000000  \n",
       "6   2127.000000     0.000000  \n",
       "5      0.000000  7086.000000  \n",
       "4   1117.697986   482.771192  \n",
       "3   2693.122246  6439.000000  \n",
       "2   4218.809324  4513.000000  \n",
       "1      0.000000     0.000000  \n",
       "0      0.000000     0.000000  \n",
       "\n",
       "[22 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtm = RatingsTransitionMatrix()\n",
    "rtm.load_rtm(data = baml)\n",
    "rtm.load_oas_change_matrix(data = baml)\n",
    "rtm.get_transition_matrix_3(csv = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class RatingsTransitionMatrix():\n",
    "\n",
    "    def __init__(self):\n",
    "        # dictionary from alphanumeric to numeric rating\n",
    "        self.ratings_map = {'AAA': 21,\n",
    "                            'AA1': 20, 'AA2': 19, 'AA3': 18,\n",
    "                            'A1': 17, 'A2': 16, 'A3': 15,\n",
    "                            'BBB1': 14, 'BBB2': 13, 'BBB3': 12,\n",
    "                            'BB1': 11, 'BB2': 10, 'BB3': 9,\n",
    "                            'B1': 8, 'B2': 7, 'B3': 6,\n",
    "                            'CCC1': 5, 'CCC2': 4, 'CCC3': 3, 'CC': 2, 'C': 1,\n",
    "                            'D': 0}\n",
    "        # dictionary from numeric to alphanumeric rating\n",
    "        self.ratings_map_inverse = {v: k for k,v in self.ratings_map.items()}\n",
    "\n",
    "        # 1. track the number of issues transitioning from one rating to another\n",
    "        # dictionary of dictionaries with rating transition **counts**. \n",
    "        # Ex: dict['A1']['BBB1'] is the number of cases where ratings went from A1 to BBB1\n",
    "        self.transition_dict = { r: collections.defaultdict(int) for r in self.ratings_map.keys()}\n",
    "        \n",
    "        # 2. track the sum of market value transitioning from one rating to another\n",
    "        # dictionary of dictionary with rating transitions by market value\n",
    "        \n",
    "        # 3. track the weighted average oas \n",
    "        self.oas_change_dict = {r: collections.defaultdict(float) for r in self.ratings_map.keys()}\n",
    "        \n",
    "\n",
    "        # dictionary with the number of times a bond started with rating X\n",
    "        self.start_counts = { r: 0.0 for r in self.ratings_map.keys()}\n",
    "\n",
    "    def load_case(self, start_rating, end_rating):\n",
    "\n",
    "        # 1. add to the ratings transition matrix\n",
    "        self.transition_dict[start_rating][end_rating] += 1\n",
    "\n",
    "        # add to total count of cases that start with a given rating\n",
    "        self.start_counts[start_rating] += 1\n",
    "    \n",
    "    def load_rtm(self, data):\n",
    "        for i in range(data.shape[0]):\n",
    "            r1 = data.loc[i, 'average_rating_0']\n",
    "            r2 = data.loc[i, 'average_rating_1']\n",
    "            if (r1 != 'NR') and (r2 != 'NR'):\n",
    "                rtm.load_case(r1, r2)\n",
    "        return None\n",
    "    \n",
    "    def load_oas_change_matrix(self, data):\n",
    "        \n",
    "        # make a copy of the data\n",
    "        temp = data[['cusip', 'mkt_val', 'average_rating_0', 'average_rating_1', 'oas_0', 'oas_1', 'oas_change']].copy()\n",
    "        mask1 = temp['average_rating_0'] != 'NR'\n",
    "        mask2 = temp['average_rating_1'] != 'NR'\n",
    "        mask3 = temp['oas_change'].notnull()\n",
    "        temp = temp[mask1 & mask2 & mask3]\n",
    "        \n",
    "        \n",
    "        # calc the weighted oas change for each rating transition\n",
    "        temp['wghtd_oas_change'] = temp['mkt_val'] * temp['oas_change']\n",
    "        top = temp.groupby(by = ['average_rating_0', 'average_rating_1'])['wghtd_oas_change'].sum()\n",
    "        bottom = temp.groupby(by = ['average_rating_0', 'average_rating_1'])['mkt_val'].sum()\n",
    "        wghtd_changes = top / bottom\n",
    "        \n",
    "        # convert to dataframe with columns average_rating_0, average_rating_1, wghtd_oas_change\n",
    "        wghtd_changes = wghtd_changes.to_frame('wghtd_oas_change')\n",
    "        wghtd_changes.reset_index(inplace = True, drop = False)\n",
    "        wghtd_changes\n",
    "        \n",
    "        # load into a dictionary\n",
    "        # iterate through each row of the dataframe and load info\n",
    "        for i in range(wghtd_changes.shape[0]):\n",
    "            r1 = wghtd_changes.loc[i, 'average_rating_0']\n",
    "            r2 = wghtd_changes.loc[i, 'average_rating_1']\n",
    "            val =  wghtd_changes.loc[i, 'wghtd_oas_change']\n",
    "            if (r1 != 'NR') and (r2 != 'NR'):\n",
    "                self.oas_change_dict[r1][r2] = val\n",
    "        return None\n",
    "        \n",
    "        \n",
    "\n",
    "    def get_transition_prob(self, start_rating, end_rating):\n",
    "        try:\n",
    "            return self.transition_dict[start_rating][end_rating] / self.start_counts[start_rating]\n",
    "        except ZeroDivisionError:\n",
    "            #return 'Error - divide by zero error. There are no cases with a starting rating of {}'.format(start_rating)\n",
    "            return np.NaN\n",
    "        except:\n",
    "            return 'unknown problem'\n",
    "\n",
    "    def get_upgrade_prob(self, start_rating):\n",
    "        if self.start_counts[start_rating] == 0:\n",
    "            return \"Sorry, can't calc upgrade prob. No cases with start rating of {}\".format(start_rating)\n",
    "        else:\n",
    "            numeric_rating = self.ratings_map[start_rating]\n",
    "            tot_prob = 0.0\n",
    "            for i in range(numeric_rating +1, 22):\n",
    "                tot_prob += self.get_transition_prob(start_rating, self.ratings_map_inverse[i])\n",
    "            return tot_prob\n",
    "\n",
    "    def get_dwngrade_prob(self, start_rating):\n",
    "        if self.start_counts[start_rating] == 0:\n",
    "            return \"Sorry, can't calc downgrade prob. No cases with start rating of {}\".format(start_rating)\n",
    "        else:\n",
    "            numeric_rating = self.ratings_map[start_rating]\n",
    "            tot_prob = 0.0\n",
    "            for i in range(numeric_rating):\n",
    "                tot_prob += self.get_transition_prob(start_rating, self.ratings_map_inverse[i])\n",
    "            return tot_prob\n",
    "\n",
    "    def get_default_prob(self, start_rating):\n",
    "        return self.get_transition_prob(start_rating, 'D')\n",
    "\n",
    "    def get_expctd_notch_chng(self, start_rating):\n",
    "        if self.start_counts[start_rating] == 0:\n",
    "            return \"Sorry, can't calc expected notch change. No cases with start rating of {}\".format(start_rating)\n",
    "        else:\n",
    "            numeric_rating = self.ratings_map[start_rating]\n",
    "            wghtd_sum = 0.0  # the weighted average notch change\n",
    "\n",
    "            #iterate over all possible end ratings\n",
    "            for i in range(0,22):\n",
    "                end_rating = self.ratings_map_inverse[i] # get the alphanumeric of the end rating\n",
    "                notch_diff = i - numeric_rating          # get the notches diff between end and start rating\n",
    "                end_rating_count = self.transition_dict[start_rating][end_rating]  # get the number of times the rating transitioned from start to end\n",
    "                wght = end_rating_count / self.start_counts[start_rating]\n",
    "                wghtd_sum += (notch_diff * wght)\n",
    "\n",
    "            return wghtd_sum\n",
    "\n",
    "    def get_transition_matrix_1(self, csv = False):\n",
    "        '''\n",
    "        transition probabilities\n",
    "        '''\n",
    "        df = pd.DataFrame()\n",
    "        df['Start']  = [self.ratings_map_inverse[x] for x in sorted(self.ratings_map_inverse.keys(), reverse = False) ]\n",
    "        df['Count'] = [self.start_counts[self.ratings_map_inverse[i]] for i in range(0, 22)]\n",
    "        for end_rating_numeric in range(21,-1,-1):\n",
    "            df[self.ratings_map_inverse[end_rating_numeric]] = \\\n",
    "                [self.get_transition_prob(self.ratings_map_inverse[i], self.ratings_map_inverse[end_rating_numeric]) for i in range(0,22)]\n",
    "        df.sort_index(ascending = False, inplace = True)\n",
    "        if csv:\n",
    "            df.to_csv('ratings_transition_matrix.csv')\n",
    "        return df\n",
    "\n",
    "    def get_transition_matrix_2(self, csv = False):\n",
    "        '''\n",
    "        transitions by bond count\n",
    "        '''\n",
    "        df = pd.DataFrame()\n",
    "        df['Start']  = [self.ratings_map_inverse[x] for x in sorted(self.ratings_map_inverse.keys(), reverse = False) ]\n",
    "        df['Count'] = [self.start_counts[self.ratings_map_inverse[i]] for i in range(0, 22)]\n",
    "        for end_rating_numeric in range(21,-1,-1):\n",
    "            df[self.ratings_map_inverse[end_rating_numeric]] = \\\n",
    "                [self.transition_dict[self.ratings_map_inverse[i]][self.ratings_map_inverse[end_rating_numeric]] for i in range(0,22)]\n",
    "        df.sort_index(ascending = False, inplace = True)\n",
    "        if csv:\n",
    "            df.to_csv('ratings_transition_matrix.csv')\n",
    "        return df\n",
    "    \n",
    "    def get_transition_matrix_3(self, csv = False):\n",
    "        '''\n",
    "        weighted-average oas changes\n",
    "        '''\n",
    "        df = pd.DataFrame()\n",
    "        df['Start']  = [self.ratings_map_inverse[x] for x in sorted(self.ratings_map_inverse.keys(), reverse = False) ]\n",
    "        df['Count'] = [self.start_counts[self.ratings_map_inverse[i]] for i in range(0, 22)]\n",
    "        for end_rating_numeric in range(21,-1,-1):\n",
    "            df[self.ratings_map_inverse[end_rating_numeric]] = \\\n",
    "                [self.oas_change_dict[self.ratings_map_inverse[i]][self.ratings_map_inverse[end_rating_numeric]] for i in range(0,22)]\n",
    "        df.sort_index(ascending = False, inplace = True)\n",
    "        if csv:\n",
    "            df.to_csv('ratings_transition_matrix.csv')\n",
    "        return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class AgencyRatings():\n",
    "\n",
    "    '''\n",
    "    Use this class to access bond-level agency rating data feeds:\n",
    "    1. get the individual agency ratings\n",
    "    2. generate agency composite ratings (ACR)\n",
    "\n",
    "    This class pulls from Y:\\QuantitativeStrategy\\data-warehouse-exports\n",
    "\n",
    "    To start, load the agency rating data feeds ingo self.moodys, self.sp, self.fitch by using load_agency_data.\n",
    "    This is a lot of data! It is therfore slow to load but once it's loaded you have fast access to\n",
    "    everything as it is stored in memory\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.moodys = None\n",
    "        self.sp = None\n",
    "        self.fitch = None\n",
    "\n",
    "        # save baml constituents for use in backfill when we need to search through the baml bonds\n",
    "        self.baml_constituents = None\n",
    "        self.baml_constituents_loaded = False\n",
    "\n",
    "    def load_agency_data(self, verbose = False):\n",
    "        '''\n",
    "        get the incremental agency ratings from data warehouse exports\n",
    "        read in moodys, sp and fitch incremental data and store as attributes of class object\n",
    "        save in self.moodys, self.sp, self.fitch\n",
    "        '''\n",
    "\n",
    "        start = timeit.default_timer()\n",
    "        moodys = pd.read_csv('Y:\\\\QuantitativeStrategy\\\\data-warehouse-exports\\\\moodys_issue_rating_history.csv')\n",
    "        #moodys = pd.read_csv('Y:\\\\QuantitativeStrategy\\\\staging-dw-exports\\\\moodys_issue_rating_history.csv')\n",
    "        #moodys = pd.read_csv('moodys_issue_rating_history.csv')\n",
    "\n",
    "        if verbose:\n",
    "            print('moodys loaded in {} seconds'.format(timeit.default_timer() - start))\n",
    "\n",
    "        start = timeit.default_timer()\n",
    "        sp = pd.read_csv('Y:\\\\QuantitativeStrategy\\\\data-warehouse-exports\\\\s_p_issue_rating_history.csv')\n",
    "        #sp = pd.read_csv('Y:\\\\QuantitativeStrategy\\\\staging-dw-exports\\\\s_p_issue_rating_history.csv')\n",
    "\n",
    "        if verbose:\n",
    "            print('sp loaded in {} seconds'.format(timeit.default_timer() - start))\n",
    "\n",
    "        # get the csv files\n",
    "        start = timeit.default_timer()\n",
    "        fitch = pd.read_csv('Y:\\\\QuantitativeStrategy\\\\data-warehouse-exports\\\\fitch_issue_rating_history.csv')\n",
    "        #fitch = pd.read_csv('Y:\\\\QuantitativeStrategy\\\\staging-dw-exports\\\\fitch_issue_rating_history.csv')\n",
    "        #fitch = pd.read_csv('fitch_issue_rating_history.csv')\n",
    "\n",
    "        if verbose:\n",
    "            print('fitch loaded in {} seconds'.format(timeit.default_timer() - start))\n",
    "\n",
    "        # the agency rating feed gives cusip as 9 digits\n",
    "        # but many sources like baml might only give 8 cusips (no check digit)\n",
    "        # for consistency, convert all cusips in the incremental agency rating data to 8 digits\n",
    "        # (for isins, assume 12 digits)\n",
    "        if verbose:\n",
    "            print('converting to 8 digit cusip')\n",
    "\n",
    "        mask = sp['id_type'].isin(['Cusip1', 'Cusip2', 'Cusip3', 'Cusip4', 'Cusip5', 'Cusip6'])\n",
    "        sp.loc[mask, 'id_value'] = sp.loc[mask, 'id_value'].map(lambda x: x[:8])\n",
    "\n",
    "        mask = fitch['id_type'].isin(['Cusip1', 'Cusip2', 'Cusip3', 'Cusip4', 'Cusip5', 'Cusip6'])\n",
    "        fitch.loc[mask, 'id_value'] = fitch.loc[mask, 'id_value'].map(lambda x: x[:8])\n",
    "\n",
    "        mask = moodys['id_type_text'].isin(['CUSIP',\n",
    "                                            'CUSIP 3',\n",
    "                                            'CUSIP 4',\n",
    "                                            'CUSIP 5',\n",
    "                                            'CUSIP - Previous',\n",
    "                                            'CUSIP - Second',\n",
    "                                            'CUSIP-2ndary Wrap Orig. CUSIP',\n",
    "                                            'CUSIP-Deriv/Underlying Bond'])\n",
    "        moodys.loc[mask, 'instrument_id_value'] = moodys.loc[mask, 'instrument_id_value'].map(lambda x: x[:8])\n",
    "\n",
    "        # for moodys, only keep certain types of ratings\n",
    "        # exclude ratings like bank credit facility, preferred stock\n",
    "        # sometimes a bond can have multiples types of ratings, but we only want the 'regular bond rating'\n",
    "        mask1 = moodys['security_class_short_description'] == 'REG'  # regular bond/debenture\n",
    "        mask2 = moodys['security_class_short_description'] == 'MTN'  # medium term note\n",
    "        mask3 = moodys['security_class_short_description'] == 'PRF'  # medium term note\n",
    "        mask4 = moodys['security_class_short_description'] == 'CON'  # medium term note\n",
    "        moodys = moodys[mask1 | mask2 | mask3 | mask4]\n",
    "\n",
    "        # exclude LGD ratings\n",
    "        mask = moodys['rating_class_text'].map(lambda x: 'LGD' in x)\n",
    "        moodys = moodys[-mask]\n",
    "\n",
    "        # save as attributes of class\n",
    "        self.moodys = moodys\n",
    "        self.sp = sp\n",
    "        self.fitch = fitch\n",
    "\n",
    "    def get_fitch_ratings(self, data, id_col, date = 'current'):\n",
    "\n",
    "        '''\n",
    "        attach a column with fitch ratings to a dataset\n",
    "\n",
    "        pass in a dataframe with a group of bonds in the rows. we want to add a new column with the fitch rating\n",
    "\n",
    "        :param data: a dataset that contains bonds that you want the rating for, as dataframe\n",
    "        :id_col: the name of the column in the datset that contains either the cusip or isin, as string\n",
    "        :param date: date(s) of the ratings you want, either 'current', a date in datetime.date, or 'incremental'\n",
    "        :return: a dataset with an added fitch_rating column, as dataframe\n",
    "        '''\n",
    "\n",
    "        original = data.copy()\n",
    "\n",
    "        # organize the bonds you want to get ratings for\n",
    "        # keep just a dataframe with a single column of bond identifiers (cusip or isin)\n",
    "        df = data.copy()\n",
    "        df = df[[id_col]]\n",
    "\n",
    "        # merge the entire incremental fitch ratings dataset and only keep bonds from the target group above\n",
    "        df = df.merge(self.fitch, how = 'left', left_on = id_col, right_on = 'id_value')\n",
    "\n",
    "\n",
    "        # data cleanup\n",
    "        # set a datetime object and sort\n",
    "        df['long_term_issue_rating_effective_date'] = pd.to_datetime(df['long_term_issue_rating_effective_date'])\n",
    "        df.sort_values(by = [id_col, 'long_term_issue_rating_effective_date'], inplace = True)\n",
    "\n",
    "        # get the ratings you want\n",
    "        # if you just want the current ratings, then keep the last rating action for each bond\n",
    "        if date == 'current':\n",
    "            df.drop_duplicates(subset = id_col, keep = 'last', inplace = True)\n",
    "        # but if you want a record of all ratings actions, don't drop anything\n",
    "        elif date == 'incremental':\n",
    "            pass\n",
    "        # and if you want a rating on a specific historical date,\n",
    "        # then keep the most recent rating prior to the historical date\n",
    "        else:\n",
    "            end_of_date = datetime.datetime(date.year, date.month, date.day, 23,59,59)\n",
    "            df = df[df['long_term_issue_rating_effective_date'] <= end_of_date]\n",
    "            df.drop_duplicates(subset = id_col, keep = 'last', inplace = True)\n",
    "\n",
    "        # data cleanup\n",
    "        fitch_fields = ['agent_common_id',\n",
    "                        'issuer_name',\n",
    "                        'fitch_issue_id_number',\n",
    "                        'id_type',\n",
    "                        'id_value',\n",
    "                        'issue_description',\n",
    "                        'long_term_issue_rating_effective_date']\n",
    "\n",
    "        # delete columns that aren't needed\n",
    "        for f in fitch_fields:\n",
    "\n",
    "            # if incremental production, then keep everything\n",
    "            if (date == 'incremental') & (f == 'long_term_issue_rating_effective_date'):\n",
    "                pass\n",
    "            # but if current or historical production, just keep the rating, rating date, and seniority\n",
    "            else:\n",
    "                del df[f]\n",
    "\n",
    "        # data cleanup\n",
    "        df.rename(columns = {'long_term_issue_rating': 'fitch_rating',\n",
    "                            'long_term_issue_rating_effective_date': 'rating_date',\n",
    "                            'issue_debt_level_code': 'fitch_seniority'}, inplace = True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_moodys_ratings(self, data, id_col, date):\n",
    "        '''\n",
    "        attach a column with moodys ratings to a dataset\n",
    "        :param data: a dataset that contains bonds that you want the rating for, as dataframe\n",
    "        :id_col: the name of the column in the datset that contains either the cusip or isin, as string\n",
    "        :param date: date(s) of the ratings you want, either 'current', a date in datetime.date format, or 'incremental'\n",
    "        :return: a dataset with an added moodys_rating column, as dataframe\n",
    "        '''\n",
    "\n",
    "\n",
    "        df = data.copy()\n",
    "        df = df[[id_col]]\n",
    "\n",
    "\n",
    "        df = df.merge(self.moodys, how = 'left', left_on = id_col, right_on = 'instrument_id_value')\n",
    "\n",
    "        df['rating_date'] = pd.to_datetime(df['rating_date'])\n",
    "        df.sort_values(by = [id_col, 'rating_date'], inplace = True)\n",
    "\n",
    "        if date == 'current':\n",
    "            df.drop_duplicates(subset = id_col, keep = 'last', inplace = True)\n",
    "        elif date == 'incremental':\n",
    "            pass\n",
    "        else:\n",
    "            end_of_date = datetime.datetime(date.year, date.month, date.day, 23,59,59)\n",
    "            df = df[df['rating_date'] <= end_of_date]\n",
    "            df.drop_duplicates(subset = id_col, keep = 'last', inplace = True)\n",
    "\n",
    "        moodys_fields = ['instrument_id',\n",
    "                         'moodys_rating_id',\n",
    "                         'security_class_short_description',\n",
    "                         'id_type_text',\n",
    "                         'instrument_id_value',\n",
    "                         'rating_date',\n",
    "                         'rating_class_text',\n",
    "                         'rating_direction_short_description',\n",
    "                         'rating_type_short_description',\n",
    "                         'rating_currency_iso_code']\n",
    "        for f in moodys_fields:\n",
    "            if (date == 'incremental') & (f == 'rating_date'):\n",
    "                pass\n",
    "            else:\n",
    "                del df[f]\n",
    "        df.rename(columns = {'rating_text': 'moodys_rating',\n",
    "                            'seniority_short_description': 'moodys_seniority'}, inplace = True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_sp_ratings(self, data, id_col, date):\n",
    "        '''\n",
    "        attach a column with S&P ratings to a dataset\n",
    "        :param data: a dataset that contains bonds that you want the rating for, as dataframe\n",
    "        :id_col: the name of the column in the datset that contains either the cusip or isin, as string\n",
    "        :param date: date(s) of the ratings you want, either 'current', a date in datetime.date format, or 'incremental'\n",
    "        :return: a dataset with an added sp_rating column, as dataframe\n",
    "        '''\n",
    "\n",
    "        df = data.copy()\n",
    "        df = df[[id_col]]\n",
    "\n",
    "        df = df.merge(self.sp, how = 'left', left_on = id_col, right_on = 'id_value')\n",
    "\n",
    "        df['rating_date'] = pd.to_datetime(df['rating_date'])\n",
    "        df.sort_values(by = [id_col, 'rating_date'], inplace = True)\n",
    "\n",
    "        if date == 'current':\n",
    "            df.drop_duplicates(subset = id_col, keep = 'last', inplace = True)\n",
    "        elif date == 'incremental':\n",
    "            pass\n",
    "        else:\n",
    "            end_of_date = datetime.datetime(date.year, date.month, date.day, 23,59,59)\n",
    "            df = df[df['rating_date'] <= end_of_date]\n",
    "            df.drop_duplicates(subset = id_col, keep = 'last', inplace = True)\n",
    "\n",
    "        sp_fields = ['security_id',\n",
    "                     'security_symbol_value',\n",
    "                     'id_type',\n",
    "                     'id_value',\n",
    "                     'rating_date']\n",
    "\n",
    "        for f in sp_fields:\n",
    "            # don't delete rating date if incremental\n",
    "            if (date == 'incremental') & (f == 'rating_date'):\n",
    "                pass\n",
    "            else:\n",
    "                del df[f]\n",
    "        df.rename(columns = {'rating': 'sp_rating'}, inplace = True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_time_series_by_id(self, data, id_col, start_date, end_date, verbose = False):\n",
    "        '''\n",
    "        generate a daily time series of ratings given a set of bonds\n",
    "        :param data: a dataset that contains bonds that you want the rating for, as dataframe\n",
    "        :id_col: the name of the column in the datset that contains either the cusip or isin, as string\n",
    "        :param start_date: start date of the time series in 'YYYY-MM-DD' format\n",
    "        :param end_date: end date of the time series in 'YYYY-MM-DD' format\n",
    "        :return: a time series dataset with an added moodys_rating, sp_rating, fitch_rating columns, as dataframe\n",
    "        '''\n",
    "\n",
    "        # get the incremental ratings from each agency for the given set of bonds\n",
    "        if verbose:\n",
    "            print('get incremental ratings for given bonds')\n",
    "        moodys = self.get_moodys_ratings(data, id_col, date = 'incremental')\n",
    "        sp = self.get_sp_ratings(data, id_col, date = 'incremental')\n",
    "        fitch = self.get_fitch_ratings(data, id_col, date = 'incremental')\n",
    "\n",
    "        if verbose:\n",
    "            print('--process incremental ratings for combination with date template')\n",
    "        for db in [moodys, sp , fitch]:\n",
    "\n",
    "            # sort by date-time\n",
    "            db.sort_values(by = [id_col, 'rating_date'], inplace = True)\n",
    "\n",
    "            # convert date-time to just dates\n",
    "            # (otherwise cannot properly merge into the date range below which are date types, not date-time types)\n",
    "            db['rating_date'] = db['rating_date'].dt.date\n",
    "\n",
    "            # keep the last action when multiple rating actions on the same date\n",
    "            db.drop_duplicates(subset = [id_col, 'rating_date'], keep = 'last', inplace = True)\n",
    "\n",
    "        # convert incremental data to daily time series\n",
    "        # generate a series with daily dates\n",
    "        if verbose:\n",
    "            print('--create a date template')\n",
    "        dates = pd.date_range(start = start_date, end = end_date, freq = 'D')\n",
    "        dates = pd.DataFrame(dates)\n",
    "        dates.rename(columns = {0: 'date'}, inplace = True)\n",
    "        dates['date'] = dates['date'].dt.date    # convert datetime to just date\n",
    "        dates['join'] = 1\n",
    "        dates['from_date_template'] = 1\n",
    "\n",
    "        # get a df with a columns of all cusips/isins\n",
    "        bonds = data.copy()\n",
    "        bonds = bonds[[id_col]]\n",
    "        bonds.drop_duplicates(subset = id_col, inplace = True)\n",
    "        bonds['join'] = 1\n",
    "\n",
    "        # combine daily date range with the bonds\n",
    "        # this will produce a dataframe with a daily observation for every bond\n",
    "        # two columns: date, bond with rows:\n",
    "        # bond1-day1\n",
    "        # bond1-day2\n",
    "        # ...\n",
    "        # bond1-dayN\n",
    "        # bond2-day1\n",
    "        # bond2-day2\n",
    "        # ...\n",
    "        # bond2-dayN\n",
    "        dates = dates.merge(bonds, how = 'left', left_on = 'join', right_on = 'join')\n",
    "        del dates['join']\n",
    "\n",
    "        # merge in the incremental moodys ratings to the date template\n",
    "        dates = dates.merge(moodys, how = 'outer', left_on = [id_col, 'date'], right_on=[id_col, 'rating_date'])\n",
    "\n",
    "        # find places where we have a rating_date but no date\n",
    "        # ie the date_range was from 2000-2017 but the first rating date was 1995\n",
    "        mask1 = (dates['date'].isnull()) & (dates['rating_date'].notnull())\n",
    "\n",
    "        # set date to rating_date in the above cases\n",
    "        dates.loc[mask1, 'date'] = dates.loc[mask1, 'rating_date']\n",
    "        del dates['rating_date']\n",
    "\n",
    "        # repeat for s&p ratings\n",
    "        dates = dates.merge(sp, how = 'outer', left_on = [id_col, 'date'], right_on=[id_col, 'rating_date'])\n",
    "        mask1 = (dates['date'].isnull()) & (dates['rating_date'].notnull())\n",
    "        dates.loc[mask1, 'date'] = dates.loc[mask1, 'rating_date']\n",
    "        del dates['rating_date']\n",
    "\n",
    "        # repeat for fitch ratings\n",
    "        dates = dates.merge(fitch, how = 'outer', left_on = [id_col, 'date'], right_on=[id_col, 'rating_date'])\n",
    "        mask1 = (dates['date'].isnull()) & (dates['rating_date'].notnull())\n",
    "        dates.loc[mask1, 'date'] = dates.loc[mask1, 'rating_date']\n",
    "        del dates['rating_date']\n",
    "\n",
    "        dates.loc[dates['from_date_template'].isnull(), 'from_date_template'] = 0\n",
    "\n",
    "        dates.sort_values(by = [id_col, 'date'], inplace = True)\n",
    "\n",
    "        # fill forward the ratings to convert from incremental to daily\n",
    "        dates = dates.groupby(by = id_col, as_index = False).fillna(method='ffill')\n",
    "\n",
    "        # drop cases that are not from the date template\n",
    "        # ie cases where we instantiate the rating at 1/1/1900\n",
    "        dates = dates[dates['from_date_template'] == 1]\n",
    "        del dates['from_date_template']\n",
    "        return dates\n",
    "\n",
    "\n",
    "\n",
    "    def get_agency_ratings_by_id(self, data, id_col, date = 'current'):\n",
    "        '''\n",
    "        pass in a dataset that contains a column with cusips that you want to get agency ratings for\n",
    "        get the agency rating for either the 'current' date or a specified historical date\n",
    "        :param data: a dataset that contains bonds that you want the rating for, as dataframe\n",
    "        :id_col: the name of the column in the datset that contains either the cusip or isin, as string\n",
    "        :param date: date(s) of the ratings you want, either 'current', a date in datetime.date format, or 'incremental'\n",
    "        :return: a dataset with an added moodys_rating column, as dataframe\n",
    "\n",
    "        '''\n",
    "\n",
    "        assert date != 'incremental', 'error: cannot use incremental ratings'\n",
    "        assert id_col in data.columns, 'error: could not find the id column in data'\n",
    "        if date != 'current':\n",
    "            assert isinstance(date, datetime.date), 'error: for non current date values you must pass date as datetime.date'\n",
    "\n",
    "        # get fitch ratings\n",
    "        fitch = self.get_fitch_ratings(data, id_col, date)\n",
    "        moodys = self.get_moodys_ratings(data, id_col, date)\n",
    "        sp = self.get_sp_ratings(data, id_col, date)\n",
    "\n",
    "        df = data.copy()\n",
    "\n",
    "        df = df.merge(moodys, how = 'left', left_on = id_col, right_on = id_col)\n",
    "\n",
    "        df = df.merge(sp, how = 'left', left_on = id_col, right_on = id_col)\n",
    "        df = df.merge(fitch, how = 'left', left_on = id_col, right_on = id_col)\n",
    "\n",
    "        for rating in ['moodys_rating', 'sp_rating', 'fitch_rating']:\n",
    "            df.loc[df[rating].isnull(), rating] = 'NR'\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_average_ratings(self, data, require_two_agencies = True):\n",
    "        '''\n",
    "        calculate the average agency rating\n",
    "        :param data: , a dataset with columns for moodys, sp and fitch alphanumeric ratings, as dataframe\n",
    "        :param require_two_agencies: require at least two agency ratings in order to calculate average, as boolean,\n",
    "        :return: the input dataset with new columns for average ratings\n",
    "        '''\n",
    "\n",
    "        for c in ['moodys_rating', 'sp_rating', 'fitch_rating']:\n",
    "            assert c in data.columns, 'error: cannot find {} in data'.format(c)\n",
    "\n",
    "        # mapping from alphanumeric to numeric rating\n",
    "        self.numeric_dict = {'AAA': 21,\n",
    "                            'AA1': 20, 'AA2': 19, 'AA3': 18,\n",
    "                            'A1': 17, 'A2': 16, 'A3': 15,\n",
    "                            'BBB1': 14, 'BBB2': 13, 'BBB3': 12,\n",
    "                            'BB1': 11, 'BB2': 10, 'BB3': 9,\n",
    "                            'B1': 8, 'B2': 7, 'B3': 6,\n",
    "                            'CCC1': 5, 'CCC2': 4, 'CCC3': 3,\n",
    "                            'CC': 2, 'C': 1, 'D': 0,\n",
    "\n",
    "                            'Aaa': 21, 'Aa1': 20, 'Aa2': 19, 'Aa3': 18,\n",
    "                            'A1': 17, 'A2': 16, 'A3': 15,\n",
    "                            'Baa1': 14, 'Baa2': 13, 'Baa3': 12,\n",
    "                            'Ba1': 11, 'Ba2': 10, 'Ba3': 9,\n",
    "                            'Caa1': 5, 'Caa2': 4, 'Caa3': 3,\n",
    "                            'Ca': 2, 'C': 1,\n",
    "\n",
    "                            'AA+': 20, 'AA': 19, 'AA-': 18,\n",
    "                            'A+': 17, 'A': 16, 'A-': 15,\n",
    "                            'BBB+': 14, 'BBB': 13, 'BBB-': 12,\n",
    "                            'BB+': 11, 'BB':10, 'BB-': 9,\n",
    "                            'B+': 8, 'B':7, 'B-': 6,\n",
    "                            'CCC+': 5, 'CCC': 4, 'CCC-': 3,\n",
    "\n",
    "                            'SD': 0, 'RD': 0, 'WR': np.NaN, 'NR': np.NaN, 'WD': np.NaN\n",
    "                             }\n",
    "\n",
    "        # mapping from numeric to alphanumeric rating\n",
    "        self.alphanumeric_dict = {21: 'AAA',\n",
    "                                  20: 'AA1', 19: 'AA2', 18: 'AA3',\n",
    "                                  17: 'A1', 16: 'A2', 15: 'A3',\n",
    "                                  14: 'BBB1', 13: 'BBB2', 12: 'BBB3',\n",
    "                                  11: 'BB1', 10: 'BB2', 9: 'BB3',\n",
    "                                  8: 'B1', 7: 'B2', 6: 'B3',\n",
    "                                  5: 'CCC1', 4: 'CCC2', 3: 'CCC3',\n",
    "                                  2: 'CC', 1: 'C', 0: 'D',\n",
    "                                  'NaN': 'NR'\n",
    "                                  }\n",
    "\n",
    "        df = data.copy()\n",
    "\n",
    "        # map alphanumeric ratings to a number\n",
    "        df['moodys_num'] = df['moodys_rating'].map(self.numeric_dict)\n",
    "        df['sp_num'] = df['sp_rating'].map(self.numeric_dict)\n",
    "        df['fitch_num'] = df['fitch_rating'].map(self.numeric_dict)\n",
    "\n",
    "        # calculate average agency rating\n",
    "        # offset numeric average by a small amount so that X.5 it gets rounded down to X and not rounded up to X + 1\n",
    "        df['average_rating_num'] = df[ ['moodys_num', 'sp_num', 'fitch_num'] ].apply(np.mean, axis = 1) - 0.0002\n",
    "        mask = df['average_rating_num'].notnull()\n",
    "        df.loc[mask, 'average_rating_num'] = df.loc[mask, 'average_rating_num'].map(round)\n",
    "        df['agency_rating_count'] = df[ ['moodys_num', 'sp_num', 'fitch_num'] ].count(axis = 1)\n",
    "\n",
    "        del df['moodys_num']\n",
    "        del df['sp_num']\n",
    "        del df['fitch_num']\n",
    "\n",
    "        # null average if less than two agency ratings\n",
    "        if require_two_agencies == True:\n",
    "            mask1 = df['agency_rating_count'] < 2\n",
    "            df.loc[mask1, 'average_rating_num'] = np.NaN\n",
    "\n",
    "        # notching based on seniority\n",
    "        # TO DO\n",
    "\n",
    "        # map numeric average to alphanumeric rating\n",
    "        df['average_rating'] = df['average_rating_num'].map(self.alphanumeric_dict)\n",
    "        df['average_rating'] = df['average_rating'].fillna('NR')\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
